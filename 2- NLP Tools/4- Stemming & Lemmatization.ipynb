{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer , LancasterStemmer,ISRIStemmer\n",
    "from nltk.stem.isri import ISRIStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egypt -- egypt\n",
      "is -- is\n",
      "a -- a\n",
      "beautiful -- beauti\n",
      "country -- countri\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = 'Egypt is a beautiful country'\n",
    "\n",
    "wtk = [word for word in word_tokenize(text)]\n",
    "\n",
    "for w in wtk : \n",
    "    print(w , '--' , ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حرك\n",
      "صلى\n",
      "درس\n"
     ]
    }
   ],
   "source": [
    "st = ISRIStemmer()\n",
    "words = ['حركات' , 'يصلى' , 'مدارس']\n",
    "\n",
    "for w in words :\n",
    "   print(st.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حمد\n",
      "يحب\n",
      "علم\n",
      "رمج\n"
     ]
    }
   ],
   "source": [
    "text = 'محمد يحب تعلم البرمجه'\n",
    "\n",
    "for w in word_tokenize(text) :\n",
    "   print(st.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Porter Stemmer      lancaster Stemmer   \n",
      "friend              friend              friend              \n",
      "friendship          friendship          friend              \n",
      "friends             friend              friend              \n",
      "friendships         friendship          friend              \n",
      "stabil              stabil              stabl               \n",
      "destabilize         destabil            dest                \n",
      "misunderstanding    misunderstand       misunderstand       \n",
      "railroad            railroad            railroad            \n",
      "moonlight           moonlight           moonlight           \n",
      "football            footbal             footbal             \n"
     ]
    }
   ],
   "source": [
    "word_list = [\"friend\", \"friendship\", \"friends\", \n",
    "\"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"] \n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\")) \n",
    "\n",
    "\n",
    "for word in word_list: \n",
    " print(\"{0:20}{1:20}{2:20}\".format(word,ps.stem(word),ls.stem(word))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 88 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Tag                  Lemma              \n",
      "I                   PRON                I                   \n",
      "am                  AUX                 be                  \n",
      "a                   DET                 a                   \n",
      "runner              NOUN                runner              \n",
      "running             VERB                run                 \n",
      "in                  ADP                 in                  \n",
      "a                   DET                 a                   \n",
      "race                NOUN                race                \n",
      "because             SCONJ               because             \n",
      "I                   PRON                I                   \n",
      "love                VERB                love                \n",
      "to                  PART                to                  \n",
      "run                 VERB                run                 \n",
      "since               SCONJ               since               \n",
      "I                   PRON                I                   \n",
      "ran                 VERB                run                 \n",
      "yesterday           NOUN                yesterday           \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I am a runner running in a race because I love to run since I ran yesterday\")\n",
    "\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Tag\",\" Lemma\")) \n",
    "for i in doc :\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(i.text, i.pos_, i.lemma_)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text): \n",
    " for token in text: \n",
    "  print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   4690420944186131903    I\n",
      "saw          VERB   11925638236994514241   see\n",
      "eighteen     NUM    9609336664675087640    eighteen\n",
      "mice         NOUN   1384165645700560590    mouse\n",
      "today        NOUN   11042482332948150395   today\n",
      "!            PUNCT  17494803046312582752   !\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"I saw eighteen mice today!\") \n",
    "\n",
    "\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats -- cat\n",
      "cacti -- cactus\n",
      "radii -- radius\n",
      "feet -- foot\n",
      "speech -- speech\n",
      "runner -- runner\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "words = [\"cats\",\"cacti\",\"radii\",\"feet\",\"speech\",'runner'] \n",
    "\n",
    "for i in words:\n",
    "    print(i , '--', lemmatizer.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meeting\n",
      "meet\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"meeting\", \"n\")) \n",
    "print(lemmatizer.lemmatize(\"meeting\",'v')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is --- be\n",
      "wa --- be\n",
      "be --- be\n",
      "been --- be\n",
      "are --- be\n",
      "were --- be\n"
     ]
    }
   ],
   "source": [
    "words = [\"is\",\"was\",\"be\",\"been\",\"are\",\"were\"] \n",
    "for word in words : \n",
    " print(lemmatizer.lemmatize(word) , '---', lemmatizer.lemmatize(word,'v')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53d50ed1839d2292cfd39f0644d59e889da85062f836d8db82f8d3a293c0c3a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
